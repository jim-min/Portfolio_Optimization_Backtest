import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import os
from alpha_vantage.cryptocurrencies import CryptoCurrencies
import dotenv
from scipy.optimize import minimize
dotenv.load_dotenv()

warnings.filterwarnings('ignore')
class PortfolioOptimizer:
    def __init__(self, symbol1='ETH', symbol2='DOT', api_key=None):
        """
        í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” í´ë˜ìŠ¤

        Parameters:
        symbol1: ì²« ë²ˆì§¸ ìì‚° (ì˜ˆ: 'ETH-USD')
        symbol2: ë‘ ë²ˆì§¸ ìì‚° (ì˜ˆ: 'DOT-USD')
        api_key: Alpha Vantage API Key (ë¬¸ìì—´)
        """
        self.symbol1, self.market1 = (symbol1.split('-') + ['USD'])[:2]
        self.symbol2, self.market2 = (symbol2.split('-') + ['USD'])[:2]

        if self.market1 != self.market2:
            raise ValueError("ë‘ ìì‚°ì˜ ë§ˆì¼“(market)ì´ ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤.")
        self.market = self.market1
        
        self.data = None
        self.returns = None
        self.results = {}
        self.api_key = os.getenv('ALPHA_VANTAGE_KEY')
        if not self.api_key:
            raise ValueError('Alpha Vantage API key must be provided!')
        self.cc = CryptoCurrencies(key=self.api_key, output_format='pandas')

    def fetch_data(self):
        # Create data directory if it doesn't exist
        os.makedirs('data', exist_ok=True)
        data_file = f'data/data_{self.symbol1}_{self.symbol2}_{self.market}.pkl'
        
        # Check if data file exists
        if os.path.exists(data_file):
            print(f"Loading data from {data_file}...")
            self.data = pd.read_pickle(data_file)
            print("Data loaded successfully!")
        else:
            print(f"{self.symbol1}-{self.market}ì™€ {self.symbol2}-{self.market} ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œ ì¤‘...")

            try:
                data1, _ = self.cc.get_digital_currency_daily(symbol=self.symbol1, market=self.market)
                print("--- API Response for symbol1 ---")
                print(data1)
                print("---------------------------------")
                data2, _ = self.cc.get_digital_currency_daily(symbol=self.symbol2, market=self.market)
                print("--- API Response for symbol2 ---")
                print(data2)
                print("---------------------------------")
                
                data1 = data1.sort_index()
                data2 = data2.sort_index()
                
                close_col_name = f'4. close'

                df = pd.DataFrame({
                    f'{self.symbol1}_price': data1[close_col_name],
                    f'{self.symbol2}_price': data2[close_col_name]
                }).dropna()

                # Save to pickle
                df.to_pickle(data_file)
                print(f"Data saved to {data_file}")
                
                self.data = df
                
            except Exception as e:
                print(f"Error fetching data: {e}")
                return
            
        # except Exception as e:
        #     print(f"Alpha Vantage ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        #     return

        self.returns = pd.DataFrame({
            f'{self.symbol1}_return': self.data[f'{self.symbol1}_price'].pct_change(),
            f'{self.symbol2}_return': self.data[f'{self.symbol2}_price'].pct_change()
        }).dropna()

        print(f"ì „ì²´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(self.data)}ê°œ ë°ì´í„°í¬ì¸íŠ¸")

    def _create_sample_data(self):
        print("ğŸ”„ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤ (ë°ëª¨ìš©)")
        dates = pd.date_range(start=self.data.index[0], end=self.data.index[-1], freq='D')
        np.random.seed(42)
        eth_returns = np.random.normal(0.001, 0.04, len(dates))
        eth_prices = 2000 * np.cumprod(1 + eth_returns)
        dot_returns = 0.7 * eth_returns + 0.3 * np.random.normal(0.0005, 0.05, len(dates))
        dot_prices = 7 * np.cumprod(1 + dot_returns)
        self.data = pd.DataFrame({
            f'{self.symbol1}_price': eth_prices,
            f'{self.symbol2}_price': dot_prices
        }, index=dates)
        self.returns = pd.DataFrame({
            f'{self.symbol1}_return': eth_returns,
            f'{self.symbol2}_return': dot_returns
        }, index=dates)
        print(f"ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(self.data)}ê°œ ë°ì´í„°í¬ì¸íŠ¸")

    def calculate_portfolio_metrics(self, weight1, weight2=None):
        """
        í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼ ì§€í‘œ ê³„ì‚°
        
        Parameters:
        weight1: ì²« ë²ˆì§¸ ìì‚° ë¹„ì¤‘ (0~1)
        weight2: ë‘ ë²ˆì§¸ ìì‚° ë¹„ì¤‘ (Noneì´ë©´ 1-weight1ë¡œ ìë™ ê³„ì‚°)
        """
        if weight2 is None:
            weight2 = 1 - weight1
            
        if self.returns is None:
            raise ValueError("ë¨¼ì € fetch_data()ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        
        # í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚°
        portfolio_returns = (weight1 * self.returns.iloc[:, 0] + 
                           weight2 * self.returns.iloc[:, 1])
        
        # ì„±ê³¼ ì§€í‘œ ê³„ì‚°
        annual_return = portfolio_returns.mean() * 252 * 100  # ì—°ê°„í™” ìˆ˜ìµë¥  (%)
        annual_volatility = portfolio_returns.std() * np.sqrt(252) * 100  # ì—°ê°„í™” ë³€ë™ì„± (%)
        sharpe_ratio = annual_return / annual_volatility if annual_volatility > 0 else 0
        
        # ìµœëŒ€ ë‚™í­ ê³„ì‚°
        cumulative_returns = (1 + portfolio_returns).cumprod()
        peak = cumulative_returns.expanding().max()
        drawdown = (cumulative_returns - peak) / peak
        max_drawdown = drawdown.min() * 100
        
        # VaR ê³„ì‚° (95% ì‹ ë¢°ìˆ˜ì¤€)
        var_95 = np.percentile(portfolio_returns, 5) * 100
        
        # ìƒê´€ê³„ìˆ˜
        correlation = self.returns.iloc[:, 0].corr(self.returns.iloc[:, 1])
        
        return {
            'weight1': weight1,
            'weight2': weight2,
            'annual_return': annual_return,
            'annual_volatility': annual_volatility,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_drawdown,
            'var_95': var_95,
            'correlation': correlation,
            'portfolio_returns': portfolio_returns
        }
    
    def efficient_frontier(self, num_portfolios=100):
        """
        íš¨ìœ¨ì  íˆ¬ìì„  ê³„ì‚°
        
        Parameters:
        num_portfolios: ê³„ì‚°í•  í¬íŠ¸í´ë¦¬ì˜¤ ê°œìˆ˜
        """
        if self.returns is None:
            raise ValueError("ë¨¼ì € fetch_data()ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        
        print("íš¨ìœ¨ì  íˆ¬ìì„  ê³„ì‚° ì¤‘...")
        
        # ë¹„ì¤‘ ë²”ìœ„ ì„¤ì • (0%~100%)
        weights1 = np.linspace(0, 1, num_portfolios)
        
        results = []
        for w1 in weights1:
            metrics = self.calculate_portfolio_metrics(w1)
            results.append(metrics)
        
        self.efficient_frontier_data = pd.DataFrame(results)
        return self.efficient_frontier_data
    
    def find_optimal_portfolios(self):
        """
        ë‹¤ì–‘í•œ ìµœì í™” ê¸°ì¤€ì— ë”°ë¥¸ ìµœì  í¬íŠ¸í´ë¦¬ì˜¤ ì°¾ê¸°
        """
        if self.returns is None:
            raise ValueError("ë¨¼ì € fetch_data()ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        
        print("ìµœì  í¬íŠ¸í´ë¦¬ì˜¤ íƒìƒ‰ ì¤‘...")
        
        # í‰ê· ê³¼ ê³µë¶„ì‚° ê³„ì‚°
        mean_returns = self.returns.mean() * 252  # ì—°ê°„í™”
        cov_matrix = self.returns.cov() * 252     # ì—°ê°„í™”
        
        def portfolio_performance(weights):
            returns = np.sum(mean_returns * weights)
            std = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
            return returns, std
        
        def negative_sharpe(weights):
            returns, std = portfolio_performance(weights)
            return -(returns / std) if std > 0 else -999
        
        def portfolio_volatility(weights):
            return portfolio_performance(weights)[1]
        
        # ì œì•½ ì¡°ê±´
        constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})
        bounds = tuple((0, 1) for _ in range(2))
        
        # 1. ìƒ¤í”„ ë¹„ìœ¨ ìµœëŒ€í™”
        result_sharpe = minimize(negative_sharpe, [0.5, 0.5], 
                               method='SLSQP', bounds=bounds, constraints=constraints)
        
        # 2. ìµœì†Œ ë³€ë™ì„±
        result_min_vol = minimize(portfolio_volatility, [0.5, 0.5],
                                method='SLSQP', bounds=bounds, constraints=constraints)
        
        # 3. ë“±ê°€ì¤‘ í¬íŠ¸í´ë¦¬ì˜¤
        equal_weight = [0.5, 0.5]
        
        # 4. ë¦¬ìŠ¤í¬ íŒ¨ë¦¬í‹° (ë³€ë™ì„± ê¸°ì—¬ë„ ë™ì¼)
        def risk_parity_objective(weights):
            portfolio_var = np.dot(weights.T, np.dot(cov_matrix, weights))
            marginal_contrib = np.dot(cov_matrix, weights)
            contrib = weights * marginal_contrib
            return np.sum((contrib - portfolio_var/2)**2)
        
        result_risk_parity = minimize(risk_parity_objective, [0.5, 0.5],
                                    method='SLSQP', bounds=bounds, constraints=constraints)
        
        # ê²°ê³¼ ì €ì¥
        optimal_portfolios = {
            'max_sharpe': {
                'weights': result_sharpe.x,
                'metrics': self.calculate_portfolio_metrics(result_sharpe.x[0], result_sharpe.x[1])
            },
            'min_volatility': {
                'weights': result_min_vol.x,
                'metrics': self.calculate_portfolio_metrics(result_min_vol.x[0], result_min_vol.x[1])
            },
            'equal_weight': {
                'weights': equal_weight,
                'metrics': self.calculate_portfolio_metrics(equal_weight[0], equal_weight[1])
            },
            'risk_parity': {
                'weights': result_risk_parity.x,
                'metrics': self.calculate_portfolio_metrics(result_risk_parity.x[0], result_risk_parity.x[1])
            }
        }
        
        self.results = optimal_portfolios
        return optimal_portfolios
    
    def monte_carlo_optimization(self, num_simulations=10000):
        """
        ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ì„ í†µí•œ ìµœì  í¬íŠ¸í´ë¦¬ì˜¤ íƒìƒ‰
        
        Parameters:
        num_simulations: ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜
        """
        if self.returns is None:
            raise ValueError("ë¨¼ì € fetch_data()ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        
        print(f"ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì¤‘... ({num_simulations:,}íšŒ)")
        
        # ëœë¤ ë¹„ì¤‘ ìƒì„±
        np.random.seed(42)
        weights1 = np.random.random(num_simulations)
        weights2 = 1 - weights1
        
        results = []
        for i in range(num_simulations):
            metrics = self.calculate_portfolio_metrics(weights1[i], weights2[i])
            results.append(metrics)
        
        mc_results = pd.DataFrame(results)
        
        # ìµœì  í¬íŠ¸í´ë¦¬ì˜¤ ì°¾ê¸°
        best_sharpe_idx = mc_results['sharpe_ratio'].idxmax()
        best_return_idx = mc_results['annual_return'].idxmax()
        min_vol_idx = mc_results['annual_volatility'].idxmin()
        min_drawdown_idx = mc_results['max_drawdown'].idxmax()  # ê°€ì¥ ì‘ì€ ë‚™í­
        
        self.mc_results = mc_results
        self.mc_optimal = {
            'best_sharpe': mc_results.loc[best_sharpe_idx],
            'best_return': mc_results.loc[best_return_idx],
            'min_volatility': mc_results.loc[min_vol_idx],
            'min_drawdown': mc_results.loc[min_drawdown_idx]
        }
        
        return mc_results, self.mc_optimal
    
    def rolling_window_analysis(self, window_months=6, rebalance_freq='M'):
        """
        ë¡¤ë§ ìœˆë„ìš°ë¥¼ í†µí•œ ì‹œê³„ì—´ ìµœì í™” ë¶„ì„
        
        Parameters:
        window_months: ë¶„ì„ ìœˆë„ìš° (ê°œì›”)
        rebalance_freq: ë¦¬ë°¸ëŸ°ì‹± ì£¼ê¸° ('M': ì›”ë³„, 'Q': ë¶„ê¸°ë³„)
        """
        if self.returns is None:
            raise ValueError("ë¨¼ì € fetch_data()ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        
        print(f"ë¡¤ë§ ìœˆë„ìš° ë¶„ì„ ì¤‘... (ìœˆë„ìš°: {window_months}ê°œì›”)")
        
        window_days = window_months * 21  # ëŒ€ëµì ì¸ ê±°ë˜ì¼ ìˆ˜
        
        # ë¦¬ë°¸ëŸ°ì‹± ë‚ ì§œ ìƒì„±
        if rebalance_freq == 'M':
            rebalance_dates = pd.date_range(start=self.returns.index[window_days], 
                                          end=self.returns.index[-1], freq='MS')
        else:  # ë¶„ê¸°ë³„
            rebalance_dates = pd.date_range(start=self.returns.index[window_days], 
                                          end=self.returns.index[-1], freq='QS')
        
        rolling_results = []
        
        for date in rebalance_dates:
            # ìœˆë„ìš° ë°ì´í„° ì¶”ì¶œ
            end_idx = self.returns.index.get_loc(date, method='nearest')
            start_idx = max(0, end_idx - window_days)
            
            window_returns = self.returns.iloc[start_idx:end_idx]
            
            if len(window_returns) < 20:  # ìµœì†Œ ë°ì´í„° ìš”êµ¬ì‚¬í•­
                continue
            
            # í•´ë‹¹ ìœˆë„ìš°ì—ì„œ ìµœì  ë¹„ì¤‘ ê³„ì‚°
            mean_returns = window_returns.mean() * 252
            cov_matrix = window_returns.cov() * 252
            
            def negative_sharpe(weights):
                returns = np.sum(mean_returns * weights)
                std = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
                return -(returns / std) if std > 0 else -999
            
            constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})
            bounds = tuple((0, 1) for _ in range(2))
            
            try:
                result = minimize(negative_sharpe, [0.5, 0.5], 
                                method='SLSQP', bounds=bounds, constraints=constraints)
                
                rolling_results.append({
                    'date': date,
                    'weight1': result.x[0],
                    'weight2': result.x[1],
                    'expected_return': np.sum(mean_returns * result.x),
                    'expected_volatility': np.sqrt(np.dot(result.x.T, np.dot(cov_matrix, result.x))),
                    'expected_sharpe': -result.fun
                })
            except:
                continue
        
        self.rolling_results = pd.DataFrame(rolling_results)
        return self.rolling_results
    
    def plot_analysis(self, figsize=(20, 15)):
        """ê²°ê³¼ ì‹œê°í™”"""
        if self.returns is None:
            raise ValueError("ë¨¼ì € ë¶„ì„ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        
        fig = plt.figure(figsize=figsize)
        
        # 1. ê°€ê²© ì°¨íŠ¸
        ax1 = plt.subplot(3, 3, 1)
        normalized_prices = self.data / self.data.iloc[0] * 100
        plt.plot(normalized_prices.index, normalized_prices.iloc[:, 0], 
                label=self.symbol1, linewidth=2)
        plt.plot(normalized_prices.index, normalized_prices.iloc[:, 1], 
                label=self.symbol2, linewidth=2)
        plt.title('ì •ê·œí™”ëœ ê°€ê²© ì¶”ì´ (ê¸°ì¤€ì =100)')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 2. íš¨ìœ¨ì  íˆ¬ìì„ 
        if hasattr(self, 'efficient_frontier_data'):
            ax2 = plt.subplot(3, 3, 2)
            ef_data = self.efficient_frontier_data
            plt.scatter(ef_data['annual_volatility'], ef_data['annual_return'], 
                       c=ef_data['sharpe_ratio'], cmap='viridis', alpha=0.6)
            plt.colorbar(label='Sharpe Ratio')
            plt.xlabel('ì—°ê°„ ë³€ë™ì„± (%)')
            plt.ylabel('ì—°ê°„ ìˆ˜ìµë¥  (%)')
            plt.title('íš¨ìœ¨ì  íˆ¬ìì„ ')
            plt.grid(True, alpha=0.3)
        
        # 3. ëª¬í…Œì¹´ë¥¼ë¡œ ê²°ê³¼
        if hasattr(self, 'mc_results'):
            ax3 = plt.subplot(3, 3, 3)
            mc_data = self.mc_results
            plt.scatter(mc_data['annual_volatility'], mc_data['annual_return'], 
                       c=mc_data['sharpe_ratio'], cmap='viridis', alpha=0.3, s=1)
            plt.colorbar(label='Sharpe Ratio')
            plt.xlabel('ì—°ê°„ ë³€ë™ì„± (%)')
            plt.ylabel('ì—°ê°„ ìˆ˜ìµë¥  (%)')
            plt.title('ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜')
            plt.grid(True, alpha=0.3)
        
        # 4. ë¹„ì¤‘ë³„ ìƒ¤í”„ ë¹„ìœ¨
        if hasattr(self, 'efficient_frontier_data'):
            ax4 = plt.subplot(3, 3, 4)
            ef_data = self.efficient_frontier_data
            plt.plot(ef_data['weight1'], ef_data['sharpe_ratio'], linewidth=2)
            plt.xlabel(f'{self.symbol1} ë¹„ì¤‘')
            plt.ylabel('ìƒ¤í”„ ë¹„ìœ¨')
            plt.title('ë¹„ì¤‘ë³„ ìƒ¤í”„ ë¹„ìœ¨')
            plt.grid(True, alpha=0.3)
        
        # 5. ë¹„ì¤‘ë³„ ìµœëŒ€ ë‚™í­
        if hasattr(self, 'efficient_frontier_data'):
            ax5 = plt.subplot(3, 3, 5)
            ef_data = self.efficient_frontier_data
            plt.plot(ef_data['weight1'], ef_data['max_drawdown'], 
                    linewidth=2, color='red')
            plt.xlabel(f'{self.symbol1} ë¹„ì¤‘')
            plt.ylabel('ìµœëŒ€ ë‚™í­ (%)')
            plt.title('ë¹„ì¤‘ë³„ ìµœëŒ€ ë‚™í­')
            plt.grid(True, alpha=0.3)
        
        # 6. ë¡¤ë§ ìµœì  ë¹„ì¤‘
        if hasattr(self, 'rolling_results'):
            ax6 = plt.subplot(3, 3, 6)
            rolling_data = self.rolling_results
            plt.plot(rolling_data['date'], rolling_data['weight1'], 
                    linewidth=2, label=f'{self.symbol1} ë¹„ì¤‘')
            plt.plot(rolling_data['date'], rolling_data['weight2'], 
                    linewidth=2, label=f'{self.symbol2} ë¹„ì¤‘')
            plt.xlabel('ë‚ ì§œ')
            plt.ylabel('ë¹„ì¤‘')
            plt.title('ì‹œê°„ë³„ ìµœì  ë¹„ì¤‘ ë³€í™”')
            plt.legend()
            plt.grid(True, alpha=0.3)
            plt.xticks(rotation=45)
        
        # 7. ìˆ˜ìµë¥  ë¶„í¬
        ax7 = plt.subplot(3, 3, 7)
        plt.hist(self.returns.iloc[:, 0], bins=50, alpha=0.7, 
                label=f'{self.symbol1}', density=True)
        plt.hist(self.returns.iloc[:, 1], bins=50, alpha=0.7, 
                label=f'{self.symbol2}', density=True)
        plt.xlabel('ì¼ì¼ ìˆ˜ìµë¥ ')
        plt.ylabel('ë°€ë„')
        plt.title('ìˆ˜ìµë¥  ë¶„í¬')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 8. ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
        ax8 = plt.subplot(3, 3, 8)
        corr_matrix = self.returns.corr()
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,
                   xticklabels=[self.symbol1, self.symbol2],
                   yticklabels=[self.symbol1, self.symbol2])
        plt.title('ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ')
        
        # 9. ëˆ„ì  ìˆ˜ìµë¥  ë¹„êµ (ìµœì  í¬íŠ¸í´ë¦¬ì˜¤ë“¤)
        if hasattr(self, 'results'):
            ax9 = plt.subplot(3, 3, 9)
            
            for name, portfolio in self.results.items():
                cumulative = (1 + portfolio['metrics']['portfolio_returns']).cumprod()
                plt.plot(cumulative.index, cumulative.values, 
                        label=f"{name} ({portfolio['weights'][0]:.1%}/{portfolio['weights'][1]:.1%})",
                        linewidth=2)
            
            plt.xlabel('ë‚ ì§œ')
            plt.ylabel('ëˆ„ì  ìˆ˜ìµë¥ ')
            plt.title('ìµœì  í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼ ë¹„êµ')
            plt.legend()
            plt.grid(True, alpha=0.3)
            plt.xticks(rotation=45)
        
        plt.tight_layout()
        plt.show()
    
    def print_summary(self):
        """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("="*80)
        print(f"ğŸ“Š {self.symbol1} vs {self.symbol2} í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ê²°ê³¼")
        print("="*80)
        
        if hasattr(self, 'results'):
            print("\nğŸ¯ ìµœì  í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ì¤‘:")
            print("-"*60)
            
            for name, portfolio in self.results.items():
                w1, w2 = portfolio['weights']
                metrics = portfolio['metrics']
                
                print(f"\nğŸ“ˆ {name.upper().replace('_', ' ')}:")
                print(f"   â€¢ {self.symbol1}: {w1:.1%} | {self.symbol2}: {w2:.1%}")
                print(f"   â€¢ ì—°ê°„ ìˆ˜ìµë¥ : {metrics['annual_return']:.2f}%")
                print(f"   â€¢ ì—°ê°„ ë³€ë™ì„±: {metrics['annual_volatility']:.2f}%")
                print(f"   â€¢ ìƒ¤í”„ ë¹„ìœ¨: {metrics['sharpe_ratio']:.3f}")
                print(f"   â€¢ ìµœëŒ€ ë‚™í­: {metrics['max_drawdown']:.2f}%")
        
        if hasattr(self, 'mc_optimal'):
            print(f"\nğŸ² ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ ìµœì í•´:")
            print("-"*60)
            
            best_sharpe = self.mc_optimal['best_sharpe']
            print(f"   â€¢ ìµœê³  ìƒ¤í”„ ë¹„ìœ¨: {self.symbol1} {best_sharpe['weight1']:.1%} | "
                  f"{self.symbol2} {best_sharpe['weight2']:.1%}")
            print(f"     ìƒ¤í”„ ë¹„ìœ¨: {best_sharpe['sharpe_ratio']:.3f}")
        
        print(f"\nğŸ“ˆ ê°œë³„ ìì‚° í†µê³„:")
        print("-"*60)
        for i, symbol in enumerate([self.symbol1, self.symbol2]):
            returns = self.returns.iloc[:, i]
            print(f"   â€¢ {symbol}:")
            print(f"     ì—°ê°„ ìˆ˜ìµë¥ : {returns.mean() * 252 * 100:.2f}%")
            print(f"     ì—°ê°„ ë³€ë™ì„±: {returns.std() * np.sqrt(252) * 100:.2f}%")
            print(f"     ìƒ¤í”„ ë¹„ìœ¨: {(returns.mean() * 252) / (returns.std() * np.sqrt(252)):.3f}")
        
        correlation = self.returns.iloc[:, 0].corr(self.returns.iloc[:, 1])
        print(f"\nğŸ”— ìƒê´€ê³„ìˆ˜: {correlation:.3f}")
        
    def run_full_analysis(self, start_date=None, end_date=None, period=None,
                         num_portfolios=100, num_simulations=10000):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        print("ğŸš€ í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # 1. ë°ì´í„° ë¡œë“œ ë° í•„í„°ë§
        self.fetch_data()
        
        if self.data is None or self.returns is None:
            print("ë°ì´í„° ë¡œë“œì— ì‹¤íŒ¨í•˜ì—¬ ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return

        # ê¸°ê°„ í•„í„°ë§
        if start_date and end_date:
            self.data = self.data.loc[start_date:end_date]
        elif period:
            # '1y', '6mo' ë“± ë¬¸ìì—´ì„ ì¼ìˆ˜ë¡œ ë³€í™˜
            def period_to_days(period_str):
                period_str = period_str.lower()
                if period_str.endswith('y'):
                    return int(period_str[:-1]) * 365
                elif period_str.endswith('mo'):
                    return int(period_str[:-2]) * 30
                elif period_str.endswith('w'):
                    return int(period_str[:-1]) * 7
                elif period_str.endswith('d'):
                    return int(period_str[:-1])
                else:
                    raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” period í˜•ì‹: {period_str}")
            days = period_to_days(period)
            from_date = pd.to_datetime('today') - pd.Timedelta(days=days)
            self.data = self.data[self.data.index >= from_date]
        
        # í•„í„°ë§ëœ ë°ì´í„°ë¡œ ìˆ˜ìµë¥  ë‹¤ì‹œ ê³„ì‚°
        self.returns = self.data.pct_change().dropna()
        
        print(f"ë¶„ì„ ê¸°ê°„: {self.data.index[0].strftime('%Y-%m-%d')} ~ {self.data.index[-1].strftime('%Y-%m-%d')}")
        print(f"ë°ì´í„°í¬ì¸íŠ¸: {len(self.data)}ê°œ")

        # 2. íš¨ìœ¨ì  íˆ¬ìì„  ê³„ì‚°
        self.efficient_frontier(num_portfolios)
        
        # 3. ìµœì  í¬íŠ¸í´ë¦¬ì˜¤ ì°¾ê¸°
        self.find_optimal_portfolios()
        
        # 4. ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜
        self.monte_carlo_optimization(num_simulations)
        
        # 5. ë¡¤ë§ ìœˆë„ìš° ë¶„ì„
        self.rolling_window_analysis()
        
        # 6. ê²°ê³¼ ì¶œë ¥
        self.print_summary()
        
        # 7. ì‹œê°í™”
        self.plot_analysis()
        
        return self.results

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ETH-DOT í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”
    optimizer = PortfolioOptimizer('ETH', 'DOT')
    
    # ì „ì²´ ë¶„ì„ ì‹¤í–‰
    results = optimizer.run_full_analysis(
        period='1y',           # ìµœê·¼ 1ë…„
        num_portfolios=100,    # íš¨ìœ¨ì  íˆ¬ìì„  í¬ì¸íŠ¸ ìˆ˜
        num_simulations=10000  # ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜
    )
    
    # íŠ¹ì • ê¸°ê°„ ë¶„ì„
    # print("\n" + "="*80)
    # print("ğŸ“… íŠ¹ì • ê¸°ê°„ ë¶„ì„ ì˜ˆì‹œ")
    
    # optimizer2 = PortfolioOptimizer('ETH', 'DOT')
    # results2 = optimizer2.run_full_analysis(
    #     start_date='2023-01-01',
    #     end_date='2024-01-01'
    # )
    
    # ë‹¤ë¥¸ ìì‚° ì¡°í•© ë¶„ì„
    # print("\n" + "="*80)
    # print("ğŸ”„ ë‹¤ë¥¸ ìì‚° ì¡°í•© ë¶„ì„")
    
    # optimizer3 = PortfolioOptimizer('BTC', 'ETH')
    # results3 = optimizer3.run_full_analysis(period='6mo')